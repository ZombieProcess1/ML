```
'''
1、决策树的构建过程需要知道如何求解熵
熵是用来衡量信息的量。一条信息包含的内容越多，越不能明晰该句子的中心思想，其熵值就越大。对于分类，类别越多，熵值也越大。下面图1显示了在分类占比平均的情况下，随着分类数量的增加，熵值的变化情况。

2、根据属性列求取对应的信息增益
对于每个属性列的多个属性值，将数据集进行了划分，针对得到的数据子集分别求熵，加权求得以该属性值分类的加权熵值。用整体熵值减去加权熵值，即得信息增益值。

3、以最大的信息增益对应的属性列划分数据集，得到数据子集，该数据子集去掉了对应的属性列
一条样本数据在被划进某个数据子集之后，是去掉了它对应的那个属性列值的。核心操作在于extend()。

4、递归第三步构造决策树，边界条件是属性用完或者分类单一

5、存储得到的决策树，以及加载决策树，避免重复训练
注解：pickle.dump()存储dict类型数据，需要用二进制存储，而不是默认的utf-8。

6、给定属性列集合进行预测
预测数据可以自拟，或者利用交叉验证方法来求取该决策树的预测错误率。

《机器学习实战》一书深入浅出，灰常适合零基础会那么点python的菜鸟哦。
'''
```

![](F:\Document\git\ML\ML\决策树_ID3\QQ图片20181128110308.png)

​                                                                                                图1